{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile dot.cu\n",
        "\n",
        "#include <iostream>         // For standard input/output operations\n",
        "#include <cuda_runtime.h>   // For CUDA runtime API\n",
        "#include <device_launch_parameters.h> // For defining CUDA kernel launch parameters\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "#define num_threads 256\n",
        "__global__ void dotProduct(float *A, float *B, float* partial_sums, float *result, int N) {\n",
        "\n",
        "  __shared__ float shemm[num_threads];\n",
        "\n",
        "  int tid = threadIdx.x;\n",
        "  int gid = blockIdx.x*blockDim.x + tid;\n",
        "  float sum;\n",
        "\n",
        "  if (gid < N) {\n",
        "    sum = A[gid] *B[gid];\n",
        "    shemm[tid] = sum;\n",
        "    }\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  //reduction logic\n",
        "  for (int s=num_threads/2; s>0; s>>=1){\n",
        "    if (tid < s){\n",
        "      shemm[tid] +=shemm[tid+s];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (tid ==0) {\n",
        "    partial_sums[blockIdx.x] = shemm[0];}\n",
        "\n",
        "\n",
        "  __threadfence();\t// Ensures writes to global memory are visible to all threads.\n",
        "\n",
        "  float finalsum=0;\n",
        "  if (blockIdx.x ==0 && tid==0){\n",
        "    for (int i=0; i<gridDim.x; i++){\n",
        "      finalsum+=partial_sums[i];\n",
        "    }\n",
        "  }\n",
        "  *result = finalsum;\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1<<16;\n",
        "    size_t size =N * sizeof(float);\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float* finalresult=(float*)malloc(sizeof(float));\n",
        "\n",
        "\n",
        "    // Initialize matrices A and B with random values\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_A[i] = 1;\n",
        "        h_B[i] = 2;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    float *d_A, *d_B, *partial_sums, *result;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc(&result, sizeof(float));\n",
        "\n",
        "\n",
        "    // Copy matrices A and B to device memory\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "\n",
        "    int numBlocks= (N / num_threads);\n",
        "\n",
        "    cudaMalloc(&partial_sums, numBlocks *sizeof(float));\n",
        "\n",
        "    // Launch the kernel\n",
        "    dotProduct<<<numBlocks, num_threads>>>(d_A, d_B, partial_sums, result,N);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "if (err != cudaSuccess) {\n",
        "    std::cout << \"CUDA Kernel Launch Error: \" << cudaGetErrorString(err) << std::endl;\n",
        "}\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(finalresult, result, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    std::cout << *finalresult;\n",
        "\n",
        "\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(result);\n",
        "    cudaFree(partial_sums);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os9fSHelerzY",
        "outputId": "f6849a82-b025-4b89-9d1a-c3116c5f3b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dot.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -gencode=arch=compute_75,code=sm_75 -o dot dot.cu"
      ],
      "metadata": {
        "id": "DYsyRojXoNhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNpH54M_RbAU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./dot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpzFs_8eoNwP",
        "outputId": "5eb4cc14-9c6d-46b6-a5a3-34e002959cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1334== NVPROF is profiling process 1334, command: ./dot\n",
            "131072==1334== Profiling application: ./dot\n",
            "==1334== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   72.90%  47.520us         2  23.760us  23.744us  23.776us  [CUDA memcpy HtoD]\n",
            "                   23.91%  15.584us         1  15.584us  15.584us  15.584us  dotProduct(float*, float*, float*, float*, int)\n",
            "                    3.19%  2.0800us         1  2.0800us  2.0800us  2.0800us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.67%  175.74ms         4  43.935ms  2.4930us  175.73ms  cudaMalloc\n",
            "                    0.10%  182.52us         3  60.839us  18.438us  85.338us  cudaMemcpy\n",
            "                    0.07%  128.88us       114  1.1300us     104ns  52.223us  cuDeviceGetAttribute\n",
            "                    0.07%  118.88us         4  29.719us  3.1580us  100.38us  cudaFree\n",
            "                    0.07%  117.10us         1  117.10us  117.10us  117.10us  cudaLaunchKernel\n",
            "                    0.01%  16.732us         1  16.732us  16.732us  16.732us  cudaDeviceSynchronize\n",
            "                    0.01%  11.877us         1  11.877us  11.877us  11.877us  cuDeviceGetName\n",
            "                    0.00%  5.4050us         1  5.4050us  5.4050us  5.4050us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.3040us         3     434ns     124ns     942ns  cuDeviceGetCount\n",
            "                    0.00%     757ns         2     378ns     143ns     614ns  cuDeviceGet\n",
            "                    0.00%     677ns         1     677ns     677ns     677ns  cuModuleGetLoadingMode\n",
            "                    0.00%     578ns         1     578ns     578ns     578ns  cudaGetLastError\n",
            "                    0.00%     555ns         1     555ns     555ns     555ns  cuDeviceTotalMem\n",
            "                    0.00%     272ns         1     272ns     272ns     272ns  cuDeviceGetUuid\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE3viTujv7nz",
        "outputId": "36200357-ef8d-4508-96fe-dbbc03d0ac8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-kqq68HBYJg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOqyYAt5YJjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXtjENetYJmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dot.cu\n",
        "\n",
        "#include <iostream>         // For standard input/output operations\n",
        "#include <cuda_runtime.h>   // For CUDA runtime API\n",
        "#include <device_launch_parameters.h> // For defining CUDA kernel launch parameters\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "#define num_threads 256\n",
        "\n",
        "__global__ void dotProduct(float *A, float *B, float* block_sums, int N) {\n",
        "\n",
        "  __shared__ float shemm[num_threads];\n",
        "\n",
        "  int tid = threadIdx.x;\n",
        "  int gid = blockIdx.x*blockDim.x + tid;\n",
        "  float sum;\n",
        "\n",
        "  if (gid < N) {\n",
        "    sum = A[gid] *B[gid];\n",
        "    shemm[tid] = sum;\n",
        "    }\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  //reduction logic\n",
        "  for (int s=num_threads/2; s>0; s>>=1){\n",
        "    if (tid < s){\n",
        "      shemm[tid] +=shemm[tid+s];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (tid ==0) {\n",
        "    block_sums[blockIdx.x] = shemm[0];}\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void addValues(float* blockSums, float* result, int N){\n",
        "\n",
        "  __shared__ float partials[num_threads];\n",
        "\n",
        "  int index=threadIdx.x;\n",
        "\n",
        "  float sum=0;\n",
        "  for (int i=index; i<N; i+=num_threads){\n",
        "    sum+=blockSums[i];\n",
        "  }\n",
        "  partials[index] = sum;\n",
        "  __syncthreads();\n",
        "\n",
        "  for (int s=num_threads/2; s>0; s>>=1){\n",
        "    if (index < s){\n",
        "      partials[index] +=partials[index+ s];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (index ==0) {\n",
        "    *result = partials[0];}\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1<<16;\n",
        "    size_t size =N * sizeof(float);\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float* finalresult=(float*)malloc(sizeof(float));\n",
        "\n",
        "\n",
        "    // Initialize matrices A and B with random values\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_A[i] = 1;\n",
        "        h_B[i] = 2;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    float *d_A, *d_B;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "\n",
        "    // Copy matrices A and B to device memory\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    int numBlocks= (N + num_threads -1)/ (num_threads);\n",
        "    float* block_sums;\n",
        "    cudaMalloc(&block_sums, numBlocks * sizeof(float));\n",
        "\n",
        "    // Launch the kernel\n",
        "    dotProduct<<<numBlocks, num_threads>>>(d_A, d_B, block_sums,N);\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "    std::cout << \"CUDA Kernel Launch Error: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    float* result;\n",
        "    cudaMalloc(&result, sizeof(float));\n",
        "\n",
        "    addValues<<<1, num_threads>>>(block_sums, result, numBlocks);  //launch reduction kernel with only 1 block.\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "    cudaMemcpy(finalresult, result, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    std::cout << *finalresult;\n",
        "\n",
        "\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(finalresult);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(result);\n",
        "    cudaFree(block_sums);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5363e83-cf45-4806-94c4-bc3d6f3dc7fe",
        "id": "GXnUMo7LYM8z"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dot.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -gencode=arch=compute_75,code=sm_75 -o dot dot.cu"
      ],
      "metadata": {
        "id": "zrIUjkzBiCRe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./dot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoIaI87miNpI",
        "outputId": "cf0a1a55-ef46-4366-e2c4-27eda7b207ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==668== NVPROF is profiling process 668, command: ./dot\n",
            "131072==668== Profiling application: ./dot\n",
            "==668== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   73.86%  48.095us         2  24.047us  24.000us  24.095us  [CUDA memcpy HtoD]\n",
            "                   15.77%  10.272us         1  10.272us  10.272us  10.272us  dotProduct(float*, float*, float*, int)\n",
            "                    7.13%  4.6400us         1  4.6400us  4.6400us  4.6400us  addValues(float*, float*, int)\n",
            "                    3.24%  2.1120us         1  2.1120us  2.1120us  2.1120us  [CUDA memcpy DtoH]\n",
            "      API calls:   98.06%  127.74ms         4  31.936ms  4.3680us  127.72ms  cudaMalloc\n",
            "                    0.83%  1.0818ms         3  360.62us  19.014us  961.06us  cudaMemcpy\n",
            "                    0.66%  864.64us         1  864.64us  864.64us  864.64us  cuDeviceGetPCIBusId\n",
            "                    0.21%  269.89us         2  134.94us  6.4380us  263.45us  cudaLaunchKernel\n",
            "                    0.11%  137.76us       114  1.2080us     104ns  50.929us  cuDeviceGetAttribute\n",
            "                    0.09%  117.06us         4  29.264us  2.6580us  102.41us  cudaFree\n",
            "                    0.02%  31.703us         1  31.703us  31.703us  31.703us  cuDeviceGetName\n",
            "                    0.02%  19.981us         2  9.9900us  8.2300us  11.751us  cudaDeviceSynchronize\n",
            "                    0.00%  1.6420us         3     547ns     138ns  1.1950us  cuDeviceGetCount\n",
            "                    0.00%     791ns         2     395ns     224ns     567ns  cuDeviceGet\n",
            "                    0.00%     541ns         1     541ns     541ns     541ns  cuDeviceTotalMem\n",
            "                    0.00%     442ns         1     442ns     442ns     442ns  cudaGetLastError\n",
            "                    0.00%     439ns         1     439ns     439ns     439ns  cuModuleGetLoadingMode\n",
            "                    0.00%     286ns         1     286ns     286ns     286ns  cuDeviceGetUuid\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
